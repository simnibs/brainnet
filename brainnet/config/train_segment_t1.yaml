PROJECT_NAME: &PROJECT SegmentT1Net

#srun -c 4 --mem=32G --gres=gpu:nvidia_geforce_rtx_3090:1 --pty bash

# results_dir/
#   checkpoints/
#     ProjectName
#   wandb/
#     ProjectName

wandb:
  enable: true
  project_name: *PROJECT
  # entity: null  # username/team name to send data to
  tags: null
  name: null      # name used to identify run in UI
  # dir: null      # sub dir of results dir

results:
  dir: !Path /mnt/scratch/personal/jesperdn/results     # PROJECT_NAME will be appended
  # checkpoints: checkpoints # store checkpoints in this subdir of dir/project/

device:
  model: cuda:0
  synthesizer: "cpu" # cuda:0

dataset:
  dir: !Path /mnt/scratch/personal/jesperdn/datasets

  train: [HCP, WH2015] #[ADNI, OASIS3]
  test: [] #[HCP]

  # which optional images to use for each dataset. Images should be valid
  optional_images:
    HCP: []
    WH2015: []

  alternative_synth:
    HCP: [norm]
    WH2015: [norm]

  split:
    rng_seed: null # seed for reproducible dataset splits (null = no seed)
    splits:
      train: 0.8
      validation: 0.2

  kwargs:
    surface_resolution: null # do not use surfaces
    # These images should be present for all datasets
    #   constants.filenames.default_images
    default_images: [segmentation, norm]
    # apply one-hot encoding to these images
    # image: labeling scheme
    onehot_encoding:
     segmentation: !LabelingScheme incl_csf

  dataloader:
    batch_size: 1
    num_workers: 2
    prefetch_factor: 2 # this seems to be PER dataset

  validation:
    image: [norm]

synthesizer:
  config: null        # config file to use. If null, use default from BrainSynth
  module: Synthesizer # Currently, there is only one synthesizer so has no effect

model: !include models/segment_t1.yaml
loss: !include loss/segment_t1.yaml


epoch:
  resume_from_checkpoint: null # e.g., 100
  max_allowed_epochs: 1000
  steps_per_epoch: 100
  steps_per_validation: 20
  validate_every: 2
  save_state_every: 20

  # resume_optim: true
  # resume_lr_scheduler: true

optimizer:
  name: AdamW
  kwargs:
    lr: 1.0e-3 # 0.001

convergence:
  minimum_lr: 1.0e-8 # 0.00000001 # 1e-8


auto_schedulers:

manual_schedulers:

