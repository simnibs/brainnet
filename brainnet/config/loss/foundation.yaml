# Specify losses for each task

# if y_pred and y_true are not specified then the task name is used to grab the relevant output and target
# module: this is essentially a wrapper around the loss function which, for
#         example, takes care of passing the correct input to the loss function
#         from brainnet.modules.task_losses
# loss: name of the actual loss function used

# Normalize loss weights to sum to one
# normalize_weights: true

# # normalize loss weights to sum to one (i.e., within tasks)
# normalize_loss_weights: true
# # normalize task weights to sum to one (i.e., across tasks)
# normalize_task_weights: true


# Entries should match the tasks of the selected model
functions:

  # Biasfield

  # bias:MSE:
  #   module:
  #     name: SoftMaskedSupervisedLoss
  #     kwargs:
  #       y_pred: biasfield
  #       y_true: biasfield
  #       mask: segmentation      # image to use for masking
  #       background_channel: 0   # channel number to use for masking (= lut.background)
  #   loss:
  #     name: torch.nn.MSELoss

  # Segmentation

  seg:DiceCE:
    module:
      name: SupervisedLoss
      kwargs: # initialization kwargs for module
        y_pred: segmentation
        y_true: segmentation
    loss:
      name: monai.losses.DiceCELoss
      kwargs: # initialization kwargs for loss function
        # include_background: false  # default = true
        softmax: true     # apply softmax before dice loss
        lambda_dice: 1.0  # default = 1.0
        lambda_ce: 1.0    # default = 1.0

  # Surface

  # Loss is averaged across lh and rh (as available)
  white:matched:
    module:
      name: SurfaceSupervisedLoss
      kwargs:
        y_pred: white
        y_true: white
    loss:
      name: brainnet.modules.losses.MatchedDistanceLoss

  white:hinge:
    module:
      name: SurfaceRegularizationLoss
      kwargs:
        y_pred: white
    loss:
      name: brainnet.modules.losses.HingeLoss

  white:chamfer:
    module:
      name: SurfaceSupervisedLoss
      kwargs:
        y_pred: white
        y_true: white
    loss:
      name: brainnet.modules.losses.SymmetricChamferLoss

  # white:curv:
  #   module:
  #     name: SurfaceSupervisedLoss
  #     kwargs:
  #       y_pred: white
  #       y_true: white
  #   loss:
  #     name: brainnet.modules.losses.SymmetricCurvatureLoss

  # white:edgelength:
  #   module:
  #     name: SurfaceRegularizationLoss
  #     kwargs:
  #       y_pred: white
  #   loss:
  #     name: brainnet.modules.losses.EdgeLengthVarianceLoss

  pial:matched:
    module:
      name: SurfaceSupervisedLoss
      kwargs:
        y_pred: pial
        y_true: pial
    loss:
      name: brainnet.modules.losses.MatchedDistanceLoss

  pial:hinge:
    module:
      name: SurfaceRegularizationLoss
      kwargs:
        y_pred: pial
    loss:
      name: brainnet.modules.losses.HingeLoss

  pial:chamfer:
    module:
      name: SurfaceSupervisedLoss
      kwargs:
        y_pred: pial
        y_true: pial
    loss:
      name: brainnet.modules.losses.SymmetricChamferLoss

  # pial:curv:
  #   module:
  #     name: SurfaceSupervisedLoss
  #     kwargs:
  #       y_pred: pial
  #       y_true: pial
  #   loss:
  #     name: brainnet.modules.losses.SymmetricCurvatureLoss

  # pial:edgelength:
  #   module:
  #     name: SurfaceRegularizationLoss
  #     kwargs:
  #       y_pred: pial
  #   loss:
  #     name: brainnet.modules.losses.EdgeLengthVarianceLoss

  # PD synthesis
  # PD:l1:
  #   module:
  #     name: SupervisedLoss
  #     kwargs:
  #       y_pred: PD
  #       y_true: PD
  #   loss:
  #     name: torch.nn.L1Loss
  # PD:dice:
  #   module:
  #     name: ModelSupervisedLoss
  #     kwargs:
  #       y_pred: PD
  #       y_true: segmentation
  #       model: !include config/model/segment_t1.yaml
  #       model_state: PathToStateDict.pt
  #   loss:
  #     name: monai.losses.DiceCELoss
  #     include_background: true


  # Optional tasks
  # T1:
  #   L1: # !ImageLoss
  #     module: ImageLoss
  #     loss: L1Loss
  #   Dice (sup):
  #     module: ModelSupervisedLoss
  #     loss: DiceLoss
  #     y_true: segmentation
  #     model: /path/to/model_t1.pt # should contain the network structure itself (variable `model`)
  #     state: /path/to/state_t1.pt # model state (variable `state_dict`)
  # CT:
  #   L1:
  #     module: ImageLoss
  #     loss: L1Loss
  #   Dice (sup):
  #     module: ModelSupervisedLoss
  #     loss: DiceLoss
  #     y_true: segmentation
  #     model: /path/to/model_ct.pt
  #     state: /path/to/state_ct.pt


# link_surface_loss: [[white:chamfer, white:curv], [pial:chamfer, pial:curv]]

weights:
  # segmentation
  seg:DiceCE: 1.0

  # surface
  white:matched: 0.01 #1.0
  white:chamfer: 1.0
  # white:curv: 1.0

  white:hinge: 1.0
  # white:edgelength: 1.0

  pial:matched: 0.01 # 1.0
  pial:chamfer: 1.0
  # pial:curv: 1.0

  pial:hinge: 1.0
  # pial:edgelength: 1.0

  # PD synthesis (optional)
  # PD:l1: 1.0
  # PD:dice: 1.0

# weights:
#   segmentation:
#     Dice: 1.0
#     CrossEntropy: 1.0
#   # biasfield:
#   #   smMSE: 1.0
#   surface:
#     white:
#       MatchedDistanceLoss: 1.0
#       SymmetricChamferLoss: 1.0
#       SymmetricCurvatureLoss: 10.0
#       EdgeLengthVarianceLoss: 1.0
#     pial:
#       MatchedDistanceLoss: 1.0
#       SymmetricChamferLoss: 1.0
#       SymmetricCurvatureLoss: 10.0
#       EdgeLengthVarianceLoss: 1.0

  # Optional tasks
  # T1:
  #   L1: 1.0
  #   Dice-SUP: 1.0
  # CT:
  #   L1: 1.0
  #   Dice-SUP: 1.0
